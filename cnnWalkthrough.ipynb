{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's get some of the necessary libraries in here\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms  \n",
    "import torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transform \n",
    "from torchvision.transforms import ToTensor, Normalize, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = \"/Users/John/Documents/allProjects/intelData/seg_train/seg_train\" \n",
    "dataTest = \"/Users/John/Documents/allProjects/intelData/seg_test/seg_test\"\n",
    "dataPred = \"/Users/John/Documents/allProjects/intelData/seg_pred/seg_pred\"\n",
    "\n",
    "## the folders in the training data give us an easy list of labels\n",
    "labels = os.listdir(dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest', 'buildings', 'glacier', 'street', 'mountain', 'sea']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing image tensors\n",
    "This process is important because it helps minimize the impact of image brightness and contrast amongst all images. Unless the images are taken school yearbook style - same location, lighting, camera, etc. - then there will inevitably be some differences among the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(dataTrain, transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "]))\n",
    "trainDL = DataLoader(train, 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## do this to extract a single image\n",
    "for (image, label) in list(enumerate(trainDL))[:1]:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dimensions are [64, 3, 64, 64] so we only need the means and sds for positions 0, 2, 3. We can discared 1 via the dim argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanSD(DL):\n",
    "    \"\"\"\n",
    "    This function will calculate the mean and sum of squared mean for the data in a\n",
    "    DataLoader. I adjusted it specifically to this dataset via the dim argument, skipping\n",
    "    index 1 because that was not the data required. This function may require other adjustments\n",
    "    for other datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    ## initialize the three variables as zero\n",
    "    runningSum, sumSquared, batches = 0,0,0\n",
    "    \n",
    "    ## extract the data from the DataLoader and calculate the sums and sum squared\n",
    "    for data, label in DL:\n",
    "        runningSum += torch.mean(data, dim = ([0,2,3]))\n",
    "        sumSquared += torch.mean(data**2, dim = ([0,2,3]))\n",
    "        batches += 1\n",
    "\n",
    "    ## simple calcs of     \n",
    "    mean = runningSum/batches\n",
    "    std = (sumSquared/batches - mean**2)**0.5\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd  = calculateMeanSD(trainDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our means and standard deviations are below. This will inform the normalize step of any transformations within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting training data\n",
    "The key here is to add in some randomness so that the CNN detects changes in the image. CNNs are shift invariant, meaning they will detect key details regardless of the position, yet they would struggle if I flipped, cropped, stretched, etc. the images. As such, we'll add in some of that randomness to help the CNN perform better on images with unique traits.\n",
    "\n",
    "To do this I, resize, add a random crop, a random color jitter, and a random horizontal flip. This is quite a bit of randomness, which should introduce the CNN to a lot of different varieties. I'll likely want to crank the epochs to make sure the CNN \"sees\" everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll do some augmentation on the training data\n",
    "trainTransform = transform.Compose([\n",
    "    transform.Resize((150,150)),\n",
    "    transform.RandomCrop((64,64)),\n",
    "    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n",
    "    transform.RandomHorizontalFlip(), ## default is p = 0.5\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize((mean[0],mean[1],mean[2]), (sd[0], sd[1], sd[2]))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not augment test data because we are evaluating the model's ability to correctly identify the images as opposed to preparing it to identify key attributes anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTransform = transform.Compose([\n",
    "    transform.Resize((150,150)),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize((mean[0],mean[1],mean[2]), (sd[0], sd[1], sd[2]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
